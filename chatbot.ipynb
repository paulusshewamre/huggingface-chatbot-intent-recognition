{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2RlhjHaaKjb/IXbTSL2Nz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulusshewamre/huggingface-chatbot-intent-recognition/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-b2Ar-0vAwFa"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers transformers qdrant-client accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies"
      ],
      "metadata": {
        "id": "y4cQ1bV9A80h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
        "import uuid\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hYFVtwOdAygm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load embedding model + chat LLM"
      ],
      "metadata": {
        "id": "5KrWzOReBDFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading models...\")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "chat_llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    max_new_tokens=80,\n",
        "    temperature=0.7\n",
        ")\n",
        "print(\"‚úÖ Models loaded.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr-jNPkXAydM",
        "outputId": "0f0f113f-0dec-4937-8dd5-356faa8a615e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Models loaded.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define intents and example sentences"
      ],
      "metadata": {
        "id": "qHdyCw7zBG46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intents = {\n",
        "    \"greeting\": {\n",
        "        \"examples\": [\"hi\", \"hello\", \"hey\", \"good morning\", \"good evening\"],\n",
        "        \"response\": \"Hey there! How are you doing today?\"\n",
        "    },\n",
        "    \"goodbye\": {\n",
        "        \"examples\": [\"bye\", \"see you\", \"goodbye\", \"catch you later\"],\n",
        "        \"response\": \"Goodbye! Talk to you soon\"\n",
        "    },\n",
        "    \"ask_weather\": {\n",
        "        \"examples\": [\"what's the weather\", \"is it raining\", \"how's the weather\"],\n",
        "        \"response\": \"It looks like a nice day! ‚òÄÔ∏è (I don‚Äôt have real-time data.)\"\n",
        "    },\n",
        "    \"ask_movie\": {\n",
        "        \"examples\": [\"recommend a movie\", \"suggest a film\", \"best sci-fi movie\"],\n",
        "        \"response\": None\n",
        "    },\n",
        "    \"ask_name\": {\n",
        "        \"examples\": [\"what's your name\", \"who are you\"],\n",
        "        \"response\": \"I'm your friendly chat assistant\"\n",
        "    },\n",
        "    \"general_chat\": {\n",
        "        \"examples\": [\"how are you\", \"what's up\", \"how's it going\"],\n",
        "        \"response\": \"I‚Äôm doing great! Thanks for asking.\"\n",
        "    },\n",
        "    \"ask_description\": {\n",
        "        \"examples\": [\"what's it about\", \"tell me more\", \"explain it\"],\n",
        "        \"response\": None\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "iGIfIf4sAyai"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode all example sentences for similarity lookup"
      ],
      "metadata": {
        "id": "ot3LZXZ5BQAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_examples = []\n",
        "intent_labels = []\n",
        "\n",
        "for intent, data in intents.items():\n",
        "    for ex in data[\"examples\"]:\n",
        "        all_examples.append(ex)\n",
        "        intent_labels.append(intent)\n",
        "\n",
        "example_embeddings = embedder.encode(all_examples)"
      ],
      "metadata": {
        "id": "C6pjxiSUAyX-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize in-memory Qdrant vector database"
      ],
      "metadata": {
        "id": "YiBTgl3LBY9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant = QdrantClient(\":memory:\")\n",
        "\n",
        "if qdrant.collection_exists(\"chat_memory\"):\n",
        "    qdrant.delete_collection(\"chat_memory\")\n",
        "\n",
        "qdrant.create_collection(\n",
        "    collection_name=\"chat_memory\",\n",
        "    vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L730trfEAyVN",
        "outputId": "64bd9c6b-d46c-4735-e4a2-56d688f2c63d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define memory storage + retrieval functions"
      ],
      "metadata": {
        "id": "pP2zIJNpBfEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def store_memory(text):\n",
        "    emb = embedder.encode(text).tolist()\n",
        "    qdrant.upsert(\n",
        "        collection_name=\"chat_memory\",\n",
        "        points=[\n",
        "            PointStruct(\n",
        "                id=str(uuid.uuid4()),\n",
        "                vector=emb,\n",
        "                payload={\"text\": text}\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def retrieve_memory(query, limit=5):\n",
        "    emb = embedder.encode(query).tolist()\n",
        "\n",
        "    results = qdrant.query_points(\n",
        "        collection_name=\"chat_memory\",\n",
        "        query=emb,\n",
        "        limit=limit\n",
        "    ).points\n",
        "\n",
        "    return [r.payload[\"text\"] for r in results]\n"
      ],
      "metadata": {
        "id": "SAJlaN5YAySb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent recognition using cosine similarity"
      ],
      "metadata": {
        "id": "NArIMTbpBktZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_intent(user_input):\n",
        "    user_emb = embedder.encode([user_input])\n",
        "    sims = np.dot(example_embeddings, user_emb.T).flatten()\n",
        "    best_idx = np.argmax(sims)\n",
        "    return intent_labels[best_idx], float(sims[best_idx])"
      ],
      "metadata": {
        "id": "VCrGY-oRAyP-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a response using intent logic + LLM"
      ],
      "metadata": {
        "id": "puIyZ7M7BnaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(user_input):\n",
        "\n",
        "    intent, score = recognize_intent(user_input)\n",
        "\n",
        "    # Confident intent classification\n",
        "    if score > 0.40:\n",
        "\n",
        "        # Movie recommendation response\n",
        "        if intent == \"ask_movie\":\n",
        "            movie = \"Inception\"\n",
        "            store_memory(f\"movie_recommendation: {movie}\")\n",
        "            return f\"You should watch *{movie}*!\"\n",
        "\n",
        "        # Movie description using memory\n",
        "        if intent == \"ask_description\":\n",
        "            memories = retrieve_memory(\"movie\")\n",
        "            for m in memories:\n",
        "                if \"movie_recommendation\" in m:\n",
        "                    movie = m.split(\":\")[1].strip()\n",
        "                    return f\"{movie} is a mind-bending sci-fi thriller about entering dreams within dreams.\"\n",
        "            return \"Tell me what exactly you want to know more about.\"\n",
        "\n",
        "        # Regular intent with predefined response\n",
        "        response = intents[intent].get(\"response\")\n",
        "        if response:\n",
        "            return response\n",
        "\n",
        "    # If intent unclear ‚Üí fallback to LLM + memory context\n",
        "    memories = retrieve_memory(user_input)\n",
        "    memory_text = \"\\n\".join(memories)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "User said: {user_input}\n",
        "Relevant memories:\n",
        "{memory_text}\n",
        "\n",
        "Respond naturally and briefly:\n",
        "\"\"\"\n",
        "\n",
        "    result = chat_llm(prompt)[0][\"generated_text\"]\n",
        "    store_memory(user_input)\n",
        "    return result.strip()"
      ],
      "metadata": {
        "id": "sSSF-W8hBrV8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run interactive chat loop"
      ],
      "metadata": {
        "id": "TJjIlbZuB4GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ü§ñ Chatbot ready! Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \").strip()\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    print(\"Bot:\", generate_response(user_input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46HmbKCRBren",
        "outputId": "959c77ea-99ec-46cd-cdc3-130b0a542340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Chatbot ready! Type 'exit' to quit.\n",
            "\n",
            "You: hi\n",
            "Bot: Hey there! How are you doing today?\n",
            "You: what's up\n",
            "Bot: I‚Äôm doing great! Thanks for asking.\n",
            "You: how is the weather like today\n",
            "Bot: It looks like a nice day! ‚òÄÔ∏è (I don‚Äôt have real-time data.)\n",
            "You: what is a good movie to watch\n",
            "Bot: You should watch *Inception*!\n",
            "You: what is it about\n",
            "Bot: Inception is a mind-bending sci-fi thriller about entering dreams within dreams.\n",
            "You: okay bye\n",
            "Bot: Goodbye! Talk to you soon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VbaoS-IBrbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}